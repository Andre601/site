{"componentChunkName":"component---src-templates-wiki-js","path":"/wiki/deployment/tuning/","result":{"data":{"mdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nconst _frontmatter = {\n  \"title\": \"Tuning Velocity\"\n};\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  let {\n    components\n  } = _ref,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Velocity comes with good performance out of the box. We go in deep, starting from smart algorithmic\\nchoices, making strategic usage of native libraries, all the way to the JVM level, optimizing\\nthe proxy so that the JVM will make better decisions when optimizing the code.\"), mdx(\"h2\", null, \"Host your servers on x86-64 Linux\"), mdx(\"p\", null, \"Velocity comes with high-performance, specially tuned native libraries for compression and\\nencryption, along with including native transports from Netty. However, due to support\\nconstraints, the compiled natives are only verified to work on Linux x86-64 and aarch64.\\nWhile Velocity will operate normally without the high-performance natives, it will suffer\\nfrom degraded performance. For this reason, we strongly recommend that all production deployments\\nof Velocity run on x86-64 Linux.\"), mdx(\"p\", null, \"It is possible for the natives to work on any other Unix-like operating system, and in theory\\nit is also possible to port the natives to Windows, but given that most users deploy Velocity on\\nLinux and lack of time and interest, it is unlikely the natives will be supported on any other platform.\"), mdx(\"p\", null, \"aarch64 support is a special case. It is forward-looking, but current aarch64 offerings are not yet\\nhigh-performance, server-grade solutions suitable for Minecraft.\"), mdx(\"h2\", null, \"Allocate server resources appropriately\"), mdx(\"p\", null, \"You should always make sure to allocate the correct amount of heap, network bandwidth, and get the right\\nCPU for the amount of players you want to have on your proxy at a given time. For instance, it is\\nunlikely you'll be able to get 1,000 players on a Raspberry Pi Zero, but you'll have a much better\\nchance if you have a recent high-end server CPU from Intel or AMD.\"), mdx(\"p\", null, \"There is no \\\"one-size-fits-all\\\" hardware recommendation, only general guidelines for the amount of players\\nyou can expect. Those guidelines are:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Prefer lots of cores but lower clock speeds. Unlike the Minecraft server, Velocity can actually benefit\\nfrom the extra cores and single-threaded performance is not as important.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The amount of memory is not as important. You will obviously need memory, but you're not going to need a\\nlot of it. 16GB of physical memory should be sufficient even for large setups that intend to handle in\\nexcess of 1,000 players.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Disk speed is unimportant. A solid-state drive is nice to have but not strictly required. Likewise, disk\\ncapacity is unimportant as well.\")), mdx(\"h2\", null, \"Allocate enough heap\"), mdx(\"p\", null, \"Alongside having enough CPU, memory, and network bandwidth, you must also allocate enough\\nJava heap to the proxy. Not doing this can induce lag and in severe cases may result in the proxy\\nbeing terminated by the Java Virtual Machine because it ran out of memory.\"), mdx(\"h3\", null, \"General recommendation\"), mdx(\"p\", null, \"The general rule of thumb is that you allocate 512MB per 500 players, plus some extra to allow\\nfor some room for error (typically 1GB extra). For instance, if you want to handle 1,000 on a single\\nproxy, plan to allocate 2GB of heap.\"), mdx(\"h3\", null, \"Special notes for containers\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"If you use a containerized setup (such as using Kubernetes, Pterodactyl, or Docker directly),\\nyou should not allocate the entirety of your memory allocation to the heap!\"), \" Doing so \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"will\"), \"\\nlikely cause the proxy to be killed by the kernel's out-of-memory killer, which will result in\\nyour proxy going down, likely at the worst possible time.\"), mdx(\"p\", null, \"A safe (albeit conservative) setting for the heap would be to allocate half of the memory you\\nallocate to the proxy container in total. For instance, if you know the proxy will need to hold\\n1,000 players, then allocate 4GB to the container and give the proxy 2GB of heap.\"), mdx(\"h2\", null, \"Tune your startup flags\"), mdx(\"p\", null, \"We also recommend tuning your startup flags. The current recommendation is:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", _extends({\n    parentName: \"div\"\n  }, {\n    \"className\": \"language-text\"\n  }), mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"-XX:+UseG1GC -XX:G1HeapRegionSize=4M -XX:+UnlockExperimentalVMOptions -XX:+ParallelRefProcEnabled -XX:+AlwaysPreTouch\"))), mdx(\"p\", null, \"You will add these flags after the \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"java\"), \" command but before the \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"-jar\"), \" parameter.\"), mdx(\"h3\", null, \"Explanation of the flags\"), mdx(\"p\", null, \"These flags focus on tuning the G1 garbage collector to be more friendly to Velocity's workload.\"), mdx(\"p\", null, \"Before the release of Java 9, the default Java garbage collector was the Parallel GC. This\\nis a stop-the-world collector that does its work in parallel. The problem is that its pause\\ntimes tend to be long, and are not suitable for Minecraft (often showing up as seemingly\\nunexplainable lag spikes).\"), mdx(\"p\", null, \"The recommended garbage collector for Velocity is the G1 region-based collector. There are\\nseveral reasons for us to recommend G1:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It strikes the right balance between throughput and pause times. Throughput is roughly how much work the\\nproxy can achieve.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"It is compatible with most setups (it is available in Java 8, the earliest Java version we support).\")), mdx(\"p\", null, \"Setups using these flags tend have very low (less than 10 millisecond) GC pauses every few minutes, which is\\nvery good for Minecraft.\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Tuning Velocity"},"excerpt":"Velocity comes with good performance out of the box. We go in deep, starting from smart algorithmic\nchoices, making strategic usage ofâ€¦"}},"pageContext":{"slug":"/deployment/tuning/"}},"staticQueryHashes":["63159454"]}